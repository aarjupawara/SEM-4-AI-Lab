import random

environment = ["A", "B", "C"]  #set

state = {
    "A": random.choice(["Clean", "Dirty"]),
    "B": random.choice(["Clean", "Dirty"]),
    "C": random.choice(["Clean", "Dirty"])
}

#initial location 
start = random.choice(environment)

#Rewards
reward_table = {
    "cleaning": 10,
    "move": -1,
    "complete": 20,
    "time-step": -0.5
}

final_reward = 0

def clean(state):
    for status in state.values():
        if status != "Clean":
            return False
    return True

print("\n")
print("Initial State:", state)
print("Initial Location:", start)
print("\n")

#simulation 
for step in range(10):
    percept = (start, state["A"], state["B"],state["C"])

    if state[start] == "Dirty":
        action = "cleaning"
        state[start] = "Clean"
        final_reward+= reward_table["cleaning"]

    elif clean(state):
        action = "complete"
        final_reward+= reward_table["complete"]
        final_reward+= reward_table["time-step"]
        print(f"Percept: {percept} | Action: {action} | Location: {start}")
        break

    else:
        action = "move"
        final_reward+= reward_table["move"]

        if start == "A":
            start = "B" if state["B"] == "Dirty" else "C"
        elif start == "B":
            start = "C" if state["C"] == "Dirty" else "A"
        else:
            start = "A" if state["A"] == "Dirty" else "B"
    
    # Time-step penalty applied every step
    final_reward += reward_table["time-step"]

    print(f"Percept: {percept} | Action: {action} | Location: {start}")

print("\n")
print("\n")
print("Final Reward:", final_reward)
